{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "F84K7w7f_eYD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "AOOvm9bk_eYG",
    "outputId": "e927f6ae-e4e2-46c9-d84d-e7d4a0816a0f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the annotated dataset\n",
    "data_df = pd.read_csv(\"ner_datasetreference.csv\", encoding=\"iso-8859-1\", header=0)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "I1tFw4LB_eYG",
    "outputId": "190933fb-a2b5-4e31-f010-d8fa5a096110"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace zero values with last valid observation\n",
    "\n",
    "data_df = data_df.fillna(method=\"ffill\")\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_Hsbghj_eYH",
    "outputId": "5dbb122d-ab5d-4251-9957-3a6d25907c59"
   },
   "outputs": [],
   "source": [
    "# count number of sentences and number of words\n",
    "\n",
    "#print(\"Total number of sentences in the dataset:\", data_df[\"Sentence #\"].nunique())\n",
    "#print(\"Total words in the dataset:\", (data_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ndj2BndV_eYH",
    "outputId": "eae2d3a3-0d0e-4350-fc82-7de6247e5617"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B-geo    37644\n",
       "B-tim    20333\n",
       "B-org    20143\n",
       "I-per    17251\n",
       "B-per    16990\n",
       "I-org    16784\n",
       "B-gpe    15870\n",
       "I-geo     7414\n",
       "I-tim     6528\n",
       "B-art      402\n",
       "B-eve      308\n",
       "I-art      297\n",
       "I-eve      253\n",
       "B-nat      201\n",
       "I-gpe      198\n",
       "I-nat       51\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count labels\n",
    "\n",
    "data_df[data_df[\"Tag\"]!=\"O\"][\"Tag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rjQOgk8_eYH",
    "outputId": "f64e4b57-57e6-4b10-b8a8-818b2a541079"
   },
   "outputs": [],
   "source": [
    "# count words for each sentences\n",
    "word_counts = data_df.groupby(\"Sentence #\")[\"Word\"].agg([\"count\"])\n",
    "#print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMv2UPLn_eYH",
    "outputId": "daefa60c-0eef-417e-d66d-a2dd8c503c23"
   },
   "outputs": [],
   "source": [
    "# define the longest sentence in the corpus\n",
    "MAX_SENTENCE = word_counts.max()[0]\n",
    "#print(MAX_SENTENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tpU9jOC_eYI",
    "outputId": "1e3d0429-94de-4287-b2ad-034cc833c3b7"
   },
   "outputs": [],
   "source": [
    "# define number of unique words and unique tags\n",
    "uniq_words = list(set(data_df[\"Word\"].values))\n",
    "uniq_tags = list(set(data_df[\"Tag\"].values))\n",
    "len_uniq_words = len(uniq_words)                   \n",
    "\n",
    "len_uniq_tag=len(uniq_tags)\n",
    "#len_uniq_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the necessary feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "r_bBOK_r_eYI"
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    build a dictionary (word2id) that assigns a unique integer value to every word from the corpus and \n",
    "    a reversed dictionary (id2word) that maps indices to words\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "word2id = {word: idx + 2 for idx, word in enumerate(uniq_words)}\n",
    "\n",
    "word2id[\"--UNKNOWN_WORD--\"]=0\n",
    "\n",
    "word2id[\"--PADDING--\"]=1\n",
    "\n",
    "id2word = {idx: word for word, idx in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqBVHF3-_eYI",
    "outputId": "a165a30c-5f33-4a25-d764-6a5e631c496d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335\n",
      "1.35\n"
     ]
    }
   ],
   "source": [
    "print(word2id[\"Crumpton\"])\n",
    "print(id2word[24640])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VL9xQ-ms_eYI"
   },
   "outputs": [],
   "source": [
    "#  build a similar dictionary for the various tags\n",
    "tag2id = {tag: idx + 1 for idx, tag in enumerate(uniq_tags)}\n",
    "tag2id[\"--PADDING--\"] = 0\n",
    "id2tag = {idx: word for word, idx in tag2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYWjzo7B_eYJ",
    "outputId": "35cee61c-1069-410d-ed08-1593a437cead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'B-tim', 2: 'I-gpe', 3: 'I-geo', 4: 'B-gpe', 5: 'B-nat', 6: 'I-org', 7: 'B-per', 8: 'I-tim', 9: 'I-art', 10: 'O', 11: 'B-org', 12: 'B-eve', 13: 'I-nat', 14: 'I-eve', 15: 'B-art', 16: 'B-geo', 17: 'I-per', 0: '--PADDING--'}\n"
     ]
    }
   ],
   "source": [
    "print(id2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8M-K5vJ9_eYJ",
    "outputId": "21322c62-1a6b-48b4-b39b-4fcf1789b084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "def create_tuples(data):\n",
    "    \n",
    "    \"\"\" return a tuple containing of each token, the part of speech it represents, and its corresponding tag\"\"\"\n",
    "    \n",
    "    iterator = zip(data[\"Word\"].values.tolist(),\n",
    "                   data[\"POS\"].values.tolist(),\n",
    "                   data[\"Tag\"].values.tolist())\n",
    "    return [(word, pos, tag) for word, pos, tag in iterator]\n",
    "\n",
    "# apply this function to the entire dataset\n",
    "sentences = data_df.groupby(\"Sentence #\").apply(create_tuples).tolist()\n",
    "\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lqq9idui_eYJ",
    "outputId": "ac7f82b0-616d-486c-9368-0d07d9ba7e37"
   },
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "     extract the features (X) and labels (y) for the model \n",
    "     discard the part of speech data, as it is not needed for this implementation.\n",
    "     \n",
    "\"\"\"\n",
    "\n",
    "X = [[word[0] for word in sentence] for sentence in sentences]\n",
    "y = [[word[2] for word in sentence] for sentence in sentences]\n",
    "\n",
    "#print(\"X[0]:\", X[0])\n",
    "#print(\"y[0]:\", y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gT-JnzM_eYJ",
    "outputId": "89e4c30c-65b7-499d-8595-a15383bb7768"
   },
   "outputs": [],
   "source": [
    "# replace each word with its corresponding index from the dictionary\n",
    "\n",
    "X = [[word2id[word] for word in sentence] for sentence in X]\n",
    "y = [[tag2id[tag] for tag in sentence] for sentence in y]\n",
    "\n",
    "#print(\"X[0]:\", X[0])\n",
    "#print(\"y[0]:\", y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lwks66cO_eYJ",
    "outputId": "08177f2e-e17f-4053-bd56-e467a2708f1c"
   },
   "outputs": [],
   "source": [
    "# for the LSTM model to process input of consistent length, eauch sentence should be padded to match the longest sentence\n",
    "\n",
    "X = [sentence + [word2id[\"--PADDING--\"]] * (MAX_SENTENCE - len(sentence)) for sentence in X]\n",
    "y = [sentence + [tag2id[\"--PADDING--\"]] * (MAX_SENTENCE - len(sentence)) for sentence in y]\n",
    "\n",
    "#print(\"X[0]:\", X[0])\n",
    "#print(\"y[0]:\", y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "j6K34PkA_eYJ"
   },
   "outputs": [],
   "source": [
    "TAG_COUNT = len(tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split data in test, development udn train \n",
    "X_main, X_test, y_main, y_test = train_test_split(X, y, test_size=0.1, random_state=1234)\n",
    "X_train,X_dev,y_train,y_dev=train_test_split(X_main, y_main, test_size=0.1, random_state=1234)\n",
    "\n",
    "#print(\"Number of sentences in the training dataset: {}\".format(len(X_train)))\n",
    "#print(\"Number of sentences in the test dataset : {}\".format(len(X_test)))\n",
    "\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
